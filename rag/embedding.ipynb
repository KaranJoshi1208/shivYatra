{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233513a2",
   "metadata": {},
   "source": [
    "## Embedding Chunked Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e65d8f",
   "metadata": {},
   "source": [
    "## Tourism Data Embedding with all-MiniLM-L6-v2\n",
    "\n",
    "**Optimized for GTX 1650 Max-Q** - Generates 384-dimensional embeddings for 4,160+ tourism chunks.\n",
    "\n",
    "**Key Features:**\n",
    "- âœ… Memory-optimized batch processing (16 chunks/batch)\n",
    "- âœ… Content enrichment with location and category metadata  \n",
    "- âœ… GPU memory management with periodic cache clearing\n",
    "- âœ… Multiple output formats (JSON + NumPy arrays)\n",
    "- âœ… Built-in quality testing with similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91552abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karan/miniconda3/envs/knji/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a85d56df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading all-MiniLM-L6-v2 model...\n",
      "âœ… Model loaded successfully!\n",
      "ğŸ“ Model output dimensions: 384\n",
      "ğŸš€ Model max sequence length: 256\n"
     ]
    }
   ],
   "source": [
    "# Load and initialize the embedding model\n",
    "print(\"ğŸ”„ Loading all-MiniLM-L6-v2 model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(f\"âœ… Model loaded successfully!\")\n",
    "print(f\"ğŸ“ Model output dimensions: {model.get_sentence_embedding_dimension()}\")\n",
    "print(f\"ğŸš€ Model max sequence length: {model.max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa13c0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading chunks from ../optimized_chunks/all_chunks_optimized.json...\n",
      "âœ… Loaded 4,160 tourism chunks\n",
      "\n",
      "ğŸ“Š Sample chunk analysis:\n",
      "   Content length: 150 characters\n",
      "   Location: India, India\n",
      "   Category: general â†’ general\n",
      "   Content preview: India (Hindi: à¤­à¤¾à¤°à¤¤ or BhÄrat), the largest country in South Asia, has many of the world's highest mo...\n"
     ]
    }
   ],
   "source": [
    "# Load the optimized tourism chunks\n",
    "def load_tourism_chunks(chunks_file: str = \"../optimized_chunks/all_chunks_optimized.json\"):\n",
    "    \"\"\"Load the chunked tourism data for embedding\"\"\"\n",
    "    print(f\"ğŸ“‚ Loading chunks from {chunks_file}...\")\n",
    "    \n",
    "    with open(chunks_file, 'r', encoding='utf-8') as f:\n",
    "        chunks = json.load(f)\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(chunks):,} tourism chunks\")\n",
    "    \n",
    "    # Display sample chunk info\n",
    "    sample_chunk = chunks[0]\n",
    "    print(f\"\\nğŸ“Š Sample chunk analysis:\")\n",
    "    print(f\"   Content length: {len(sample_chunk['content'])} characters\")\n",
    "    print(f\"   Location: {sample_chunk['location']['city']}, {sample_chunk['location']['state']}\")\n",
    "    print(f\"   Category: {sample_chunk['classification']['category']} â†’ {sample_chunk['classification']['subcategory']}\")\n",
    "    print(f\"   Content preview: {sample_chunk['content'][:100]}...\")\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Load the chunks\n",
    "tourism_chunks = load_tourism_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e23b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Preparing content for embedding...\n",
      "âœ… Prepared 4,160 items for embedding\n",
      "ğŸ“ Sample enriched content:\n",
      "   Original: India (Hindi: à¤­à¤¾à¤°à¤¤ or BhÄrat), the largest country in South Asia, has many of th...\n",
      "   Enriched: India (Hindi: à¤­à¤¾à¤°à¤¤ or BhÄrat), the largest country in South Asia, has many of the world's highest mountains, most popula...\n"
     ]
    }
   ],
   "source": [
    "# Prepare content for embedding\n",
    "def prepare_embedding_content(chunks):\n",
    "    \"\"\"Prepare optimized content for embedding generation\"\"\"\n",
    "    embedding_data = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Create rich content for embedding by combining content with metadata\n",
    "        content = chunk['content']\n",
    "        \n",
    "        # Add location context for better geographic understanding\n",
    "        location_context = f\"{chunk['location']['city']}, {chunk['location']['state']}\"\n",
    "        \n",
    "        # Add category context for better semantic understanding  \n",
    "        category_context = f\"{chunk['classification']['category']} - {chunk['classification']['subcategory']}\"\n",
    "        \n",
    "        # Combine content with minimal metadata for better embeddings\n",
    "        enriched_content = f\"{content} Location: {location_context}. Category: {category_context}\"\n",
    "        \n",
    "        embedding_data.append({\n",
    "            'chunk_id': chunk['chunk_id'],\n",
    "            'original_content': content,\n",
    "            'embedding_content': enriched_content,\n",
    "            'metadata': {\n",
    "                'location': chunk['location'],\n",
    "                'classification': chunk['classification'],\n",
    "                'practical_info': chunk['practical_info'],\n",
    "                'relevance_scores': chunk['relevance_scores']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return embedding_data\n",
    "\n",
    "# Prepare embedding content\n",
    "print(\"ğŸ”„ Preparing content for embedding...\")\n",
    "embedding_data = prepare_embedding_content(tourism_chunks)\n",
    "\n",
    "print(f\"âœ… Prepared {len(embedding_data):,} items for embedding\")\n",
    "print(f\"ğŸ“ Sample enriched content:\")\n",
    "print(f\"   Original: {embedding_data[0]['original_content'][:80]}...\")\n",
    "print(f\"   Enriched: {embedding_data[0]['embedding_content'][:120]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b39e4a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Generating embeddings optimized for GTX 1650 Max-Q...\n",
      "ğŸ“Š Processing 4,160 texts\n",
      "ğŸ”§ Batch size: 16 (optimized for 4GB VRAM)\n",
      "ğŸ’¾ Expected output dimensions: 384\n",
      "â±ï¸ Estimated time: ~5-15 minutes\n",
      "ğŸ¯ Using device: cuda\n",
      "ğŸ”§ GPU: NVIDIA GeForce GTX 1650\n",
      "ğŸ’¾ GPU Memory: 3.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:08<00:00, 29.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Embedding generation complete!\n",
      "ğŸ“ Shape: (4160, 384)\n",
      "ğŸ“Š Dimensions per embedding: 384\n",
      "ğŸ’¾ Total size: 6.09 MB\n",
      "â±ï¸ Processing time: 9.0 seconds\n",
      "ğŸš€ Speed: 463.9 chunks/second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings with all-MiniLM-L6-v2 - Optimized for GTX 1650 Max-Q\n",
    "def generate_embeddings_batch(model, texts, batch_size=16):  # Reduced batch size for GTX 1650\n",
    "    \"\"\"Generate embeddings in batches optimized for GTX 1650 Max-Q\"\"\"\n",
    "    all_embeddings = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(f\"ğŸ¯ Using device: {device}\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"ğŸ”§ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating embeddings\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Generate embeddings with memory management\n",
    "        with torch.no_grad():\n",
    "            embeddings = model.encode(\n",
    "                batch_texts, \n",
    "                convert_to_tensor=True, \n",
    "                device=device,\n",
    "                show_progress_bar=False  # Disable inner progress bar\n",
    "            )\n",
    "            # Move to CPU and convert to numpy to free GPU memory\n",
    "            embeddings = embeddings.cpu().numpy()\n",
    "            all_embeddings.extend(embeddings)\n",
    "        \n",
    "        # Clear GPU cache periodically for GTX 1650\n",
    "        if device.type == 'cuda' and i % (batch_size * 10) == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return np.array(all_embeddings)\n",
    "\n",
    "# Extract texts for embedding\n",
    "embedding_texts = [item['embedding_content'] for item in embedding_data]\n",
    "\n",
    "print(\"ğŸš€ Generating embeddings optimized for GTX 1650 Max-Q...\")\n",
    "print(f\"ğŸ“Š Processing {len(embedding_texts):,} texts\")\n",
    "print(f\"ğŸ”§ Batch size: 16 (optimized for 4GB VRAM)\")\n",
    "print(f\"ğŸ’¾ Expected output dimensions: 384\")\n",
    "print(f\"â±ï¸ Estimated time: ~5-15 minutes\")\n",
    "\n",
    "# Generate embeddings\n",
    "start_time = time.time()\n",
    "embeddings = generate_embeddings_batch(model, embedding_texts)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nâœ… Embedding generation complete!\")\n",
    "print(f\"ğŸ“ Shape: {embeddings.shape}\")\n",
    "print(f\"ğŸ“Š Dimensions per embedding: {embeddings.shape[1]}\")\n",
    "print(f\"ğŸ’¾ Total size: {embeddings.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"â±ï¸ Processing time: {end_time - start_time:.1f} seconds\")\n",
    "print(f\"ğŸš€ Speed: {len(embedding_texts) / (end_time - start_time):.1f} chunks/second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "455f7c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created comprehensive embedding dataset\n",
      "ğŸ“Š Total entries: 4,160\n",
      "ğŸ“ Embedding dimensions: 384\n",
      "\n",
      "ğŸ” Sample embedding analysis:\n",
      "   Chunk ID: in_in_india_gen_gen_001\n",
      "   Content: India (Hindi: à¤­à¤¾à¤°à¤¤ or BhÄrat), the largest country in South Asia, has many of th...\n",
      "   Embedding norm: 1.0000\n",
      "   First 5 dimensions: [0.058542847633361816, 0.0032589775510132313, -0.06868673115968704, -0.018095869570970535, -0.008678180165588856]\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive embedding dataset\n",
    "embedding_dataset = []\n",
    "\n",
    "for i, (chunk_data, embedding) in enumerate(zip(embedding_data, embeddings)):\n",
    "    entry = {\n",
    "        'chunk_id': chunk_data['chunk_id'],\n",
    "        'content': chunk_data['original_content'],\n",
    "        'enriched_content': chunk_data['embedding_content'],\n",
    "        'embedding': embedding.tolist(),  # Convert numpy array to list for JSON serialization\n",
    "        'metadata': chunk_data['metadata'],\n",
    "        'embedding_info': {\n",
    "            'model': 'all-MiniLM-L6-v2',\n",
    "            'dimensions': len(embedding),\n",
    "            'norm': float(np.linalg.norm(embedding))\n",
    "        }\n",
    "    }\n",
    "    embedding_dataset.append(entry)\n",
    "\n",
    "print(f\"âœ… Created comprehensive embedding dataset\")\n",
    "print(f\"ğŸ“Š Total entries: {len(embedding_dataset):,}\")\n",
    "print(f\"ğŸ“ Embedding dimensions: {embedding_dataset[0]['embedding_info']['dimensions']}\")\n",
    "\n",
    "# Sample embedding analysis\n",
    "sample_embedding = embedding_dataset[0]\n",
    "print(f\"\\nğŸ” Sample embedding analysis:\")\n",
    "print(f\"   Chunk ID: {sample_embedding['chunk_id']}\")\n",
    "print(f\"   Content: {sample_embedding['content'][:80]}...\")\n",
    "print(f\"   Embedding norm: {sample_embedding['embedding_info']['norm']:.4f}\")\n",
    "print(f\"   First 5 dimensions: {sample_embedding['embedding'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af7443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saving embedding dataset to: embeddings/tourism_embeddings_all_MiniLM_L6_v2.json\n",
      "ğŸ“Š Dataset size: 4,160 entries\n",
      "âœ… Embeddings saved successfully!\n",
      "ğŸ“ File: embeddings/tourism_embeddings_all_MiniLM_L6_v2.json\n",
      "ğŸ“Š File size: 47.43 MB\n",
      "ğŸ¯ Numpy embeddings saved: embeddings/tourism_embeddings_vectors.npy\n",
      "ğŸ“ Shape: (4160, 384)\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings to file\n",
    "import json\n",
    "\n",
    "# Create embeddings directory if it doesn't exist\n",
    "embeddings_dir = Path(\"embeddings\")\n",
    "embeddings_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the complete embedding dataset\n",
    "embeddings_file = embeddings_dir / \"tourism_embeddings_all_MiniLM_L6_v2.json\"\n",
    "\n",
    "print(f\"ğŸ’¾ Saving embedding dataset to: {embeddings_file}\")\n",
    "print(f\"ğŸ“Š Dataset size: {len(embedding_dataset):,} entries\")\n",
    "\n",
    "with open(embeddings_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(embedding_dataset, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Calculate file size\n",
    "file_size_mb = embeddings_file.stat().st_size / 1024 / 1024\n",
    "\n",
    "print(f\"âœ… Embeddings saved successfully!\")\n",
    "print(f\"ğŸ“ File: {embeddings_file}\")\n",
    "print(f\"ğŸ“Š File size: {file_size_mb:.2f} MB\")\n",
    "\n",
    "# Also save just the embedding vectors as numpy array for faster loading\n",
    "embeddings_numpy_file = embeddings_dir / \"tourism_embeddings_vectors.npy\"\n",
    "np.save(embeddings_numpy_file, embeddings)\n",
    "\n",
    "print(f\"ğŸ¯ Numpy embeddings saved: {embeddings_numpy_file}\")\n",
    "print(f\"ğŸ“ Shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e60ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing embedding quality with sample queries...\n",
      "ğŸ¯ Model: all-MiniLM-L6-v2 (384 dimensions)\n",
      "ğŸ“Š Testing against 4,160 tourism chunks\n",
      "\n",
      "--- Query 1: 'adventure activities in Himachal Pradesh mountains' ---\n",
      "  1. Similarity: 0.7549\n",
      "     Content: Friendship Peak Expedition â€“ Trek to one of the majestic mountains; Friendship Peak, in the beautifu...\n",
      "     Category: activities\n",
      "     Location: Himachal Pradesh, Himachal\n",
      "  2. Similarity: 0.7492\n",
      "     Content: If planning for a trek up the beautiful mountains, don't forget to hire a local guide. As the local ...\n",
      "     Category: activities\n",
      "     Location: Kullu, Himachal\n",
      "  3. Similarity: 0.7387\n",
      "     Content: River rafting, skiing, zorbing, trekking, snow scootering, and river crossing. One of the best adven...\n",
      "     Category: activities\n",
      "     Location: Manali, Himachal\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "--- Query 2: 'traditional food in Almora' ---\n",
      "  1. Similarity: 0.5699\n",
      "     Content: Almora is an agricultural base and also a trade centre....\n",
      "     Category: general\n",
      "     Location: Almora, Uttarakhand\n",
      "  2. Similarity: 0.5661\n",
      "     Content: There are no Chinese or East-Asian inspired dishes on the menu here. (updated Jun 2022)...\n",
      "     Category: dining\n",
      "     Location: Almora, Uttarakhand\n",
      "  3. Similarity: 0.5601\n",
      "     Content: 1 Pizza Wok Cafe, Mall Rd, Dharanaula (near Paltan Bazar). Daily 9AM-10PM. The oldest pizza cafe in ...\n",
      "     Category: dining\n",
      "     Location: Almora, Uttarakhand\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "--- Query 3: 'heritage sites in Uttarakhand' ---\n",
      "  1. Similarity: 0.6707\n",
      "     Content: Beware, the following listing looks like toutingâ€”please inquire also other opportunities locally....\n",
      "     Category: activities\n",
      "     Location: Nanda Devi National Park, Uttarakhand\n",
      "  2. Similarity: 0.6581\n",
      "     Content: The temple is aesthetically not particularly noteworthy, but the views are grand...\n",
      "     Category: activities\n",
      "     Location: Haridwar, Uttarakhand\n",
      "  3. Similarity: 0.6086\n",
      "     Content: A museum displaying the geological diversity of the sub-continent is the center of attraction here a...\n",
      "     Category: activities\n",
      "     Location: Dehradun, Uttarakhand\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    }
   ],
   "source": [
    "# Test embedding quality with sample queries\n",
    "def find_similar_chunks(query, embeddings, embedding_data, model, top_k=5):\n",
    "    \"\"\"Find similar chunks using cosine similarity\"\"\"\n",
    "    # Generate embedding for query\n",
    "    query_embedding = model.encode([query])\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarities = np.dot(embeddings, query_embedding.T).flatten()\n",
    "    \n",
    "    # Get top-k most similar chunks\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            'similarity': float(similarities[idx]),\n",
    "            'content': embedding_data[idx]['original_content'],\n",
    "            'metadata': embedding_data[idx]['metadata'],\n",
    "            'chunk_id': embedding_data[idx]['chunk_id']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test with sample tourism queries\n",
    "test_queries = [\n",
    "    # \"best places to visit in Goa beaches\",\n",
    "    \"adventure activities in Himachal Pradesh mountains\", \n",
    "    # \"budget accommodation in Delhi\",\n",
    "    \"traditional food in Almora\",\n",
    "    \"heritage sites in Uttarakhand\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Testing embedding quality with sample queries...\")\n",
    "print(f\"ğŸ¯ Model: all-MiniLM-L6-v2 (384 dimensions)\")\n",
    "print(f\"ğŸ“Š Testing against {len(embeddings):,} tourism chunks\")\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n--- Query {i}: '{query}' ---\")\n",
    "    results = find_similar_chunks(query, embeddings, embedding_data, model, top_k=3)\n",
    "    \n",
    "    for j, result in enumerate(results, 1):\n",
    "        print(f\"  {j}. Similarity: {result['similarity']:.4f}\")\n",
    "        print(f\"     Content: {result['content'][:100]}...\")\n",
    "        print(f\"     Category: {result['metadata']['classification']['category']}\")\n",
    "        print(f\"     Location: {result['metadata']['location']['city']}, {result['metadata']['location']['state']}\")\n",
    "    print(\"  \" + \"â”€\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec68d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ EMBEDDING GENERATION COMPLETE!\n",
      "==================================================\n",
      "ğŸ“Š Model: all-MiniLM-L6-v2 (384 dimensions)\n",
      "ğŸ“ˆ Processed: 4,160 tourism chunks\n",
      "ğŸ’¾ Output size: 6.1 MB\n",
      "ğŸ“ Files saved: JSON dataset + NumPy vectors\n",
      "ğŸš€ Ready for RAG integration with vector database!\n"
     ]
    }
   ],
   "source": [
    "# Embedding generation summary\n",
    "print(\"\\nğŸ¯ EMBEDDING GENERATION COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ğŸ“Š Model: all-MiniLM-L6-v2 (384 dimensions)\")\n",
    "print(f\"ğŸ“ˆ Processed: {len(embeddings):,} tourism chunks\")\n",
    "print(f\"ğŸ’¾ Output size: {embeddings.nbytes / 1024 / 1024:.1f} MB\")\n",
    "print(f\"ğŸ“ Files saved: JSON dataset + NumPy vectors\")\n",
    "print(f\"ğŸš€ Ready for RAG integration with vector database!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
